{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful for debugging\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/chrisonian/Code/GitHub/lume-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import h5py\n",
    "from time import time\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt import parsers, tools, writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT:\n",
    "    \"\"\" \n",
    "    GPT simulation object. Essential methods:\n",
    "    .__init__(...)\n",
    "    .configure()\n",
    "    .run()\n",
    "    \n",
    "    Input deck is held in .input\n",
    "    Output data is parsed into .output\n",
    "    .load_screens() will load particle data into .screen[...]\n",
    "    \n",
    "    The GPT binary file can be set on init. If it doesn't exist, configure will check the\n",
    "        $GPT_BIN\n",
    "    environmental variable.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_file=None,\n",
    "                 gpt_bin='$GPT_BIN',      \n",
    "                 use_tempdir=True,\n",
    "                 workdir=None,\n",
    "                 verbose=False):\n",
    "        # Save init\n",
    "        self.original_input_file = input_file\n",
    "        self.use_tempdir = use_tempdir\n",
    "        self.workdir = workdir\n",
    "        if workdir:\n",
    "            assert os.path.exists(workdir), 'workdir does not exist: '+workdir        \n",
    "        self.verbose=verbose\n",
    "        self.gpt_bin = gpt_bin\n",
    "\n",
    "        # These will be set\n",
    "        self.log = []\n",
    "        self.output = {}\n",
    "        self.screen = [] # list of screens\n",
    "        self.timeout=None\n",
    "        self.error = False\n",
    "        \n",
    "        # Run control\n",
    "        self.finished = False\n",
    "        self.configured = False\n",
    "        self.using_tempdir = False\n",
    "        \n",
    "        # Call configure\n",
    "        if input_file:\n",
    "            self.load_input(input_file)\n",
    "            self.configure()\n",
    "        else:\n",
    "            self.vprint('Warning: Input file does not exist. Not configured.')\n",
    "\n",
    "\n",
    "                   \n",
    "\n",
    "    def configure(self):\n",
    "        self.configure_gpt(workdir=self.workdir)\n",
    " \n",
    "    def configure_gpt(self, input_filePath=None, workdir=None):\n",
    "        \n",
    "        if input_filePath:\n",
    "            self.load_input(input_filePath)\n",
    "        \n",
    "        # Check that binary exists\n",
    "        self.gpt_bin = tools.full_path(self.gpt_bin)\n",
    "        assert os.path.exists(self.gpt_bin), 'ERROR: GPT binary does not exist:'+self.gpt_bin\n",
    "              \n",
    "        # Set paths\n",
    "        if self.use_tempdir:\n",
    "            # Need to attach this to the object. Otherwise it will go out of scope.\n",
    "            self.tempdir = tempfile.TemporaryDirectory(dir=workdir)\n",
    "            self.path = self.tempdir.name\n",
    "        else:\n",
    "            # Work in place\n",
    "            self.path = self.original_path            \n",
    "\n",
    "        self.input_file = os.path.join(self.path, self.original_input_file)                \n",
    "        self.configured = True\n",
    "    \n",
    "    \n",
    "    def load_input(self, input_filePath, absolute_paths=True):\n",
    "        f = tools.full_path(input_filePath)\n",
    "        self.original_path, self.original_input_file = os.path.split(f) # Get original path, filename\n",
    "        \n",
    "        #TODO\n",
    "        #self.input = parsers.parse_astra_input_file(f)            \n",
    "            \n",
    "            \n",
    "    def load_output(self):\n",
    "        #TODO\n",
    "        pass\n",
    "                \n",
    "    def load_screens(self, end_only=False):\n",
    "        # Clear existing screens\n",
    "        self.screen = []\n",
    "        \n",
    "        #TODO\n",
    "        \n",
    "        \n",
    "        \n",
    "    def run(self):\n",
    "        if not self.configured:\n",
    "            print('not configured to run')\n",
    "            return\n",
    "        self.run_gpt(verbose=self.verbose, timeout=self.timeout)\n",
    "        \n",
    "    \n",
    "        \n",
    "    def get_run_script(self, write_to_path=True):\n",
    "        \"\"\"\n",
    "        Assembles the run script. Optionally writes a file 'run' with this line to path.\n",
    "        \"\"\"\n",
    "        \n",
    "        _, infile = os.path.split(self.input_file)\n",
    "        \n",
    "        runscript = [self.gpt_bin, infile]\n",
    "            \n",
    "        if write_to_path:\n",
    "            with open(os.path.join(self.path, 'run'), 'w') as f:\n",
    "                f.write(' '.join(runscript))\n",
    "            \n",
    "        return runscript\n",
    "\n",
    "        \n",
    "    \n",
    "    def run_gpt(self, verbose=False, parse_output=True, timeout=None):\n",
    "\n",
    "        \n",
    "        run_info = {}\n",
    "        t1 = time()\n",
    "        run_info['start_time'] = t1\n",
    "        \n",
    "        # Move to local directory\n",
    "\n",
    "        # Save init dir\n",
    "        init_dir = os.getcwd()\n",
    "        self.vprint('init dir: ', init_dir)\n",
    "        \n",
    "        os.chdir(self.path)\n",
    "        # Debugging\n",
    "        self.vprint('running GPT in '+os.getcwd())\n",
    "\n",
    "        # Write input file from internal dict\n",
    "        self.write_input_file()\n",
    "        \n",
    "        runscript = self.get_run_script()\n",
    "    \n",
    "        try:\n",
    "            if timeout:\n",
    "                res = tools.execute2(runscript, timeout=timeout)\n",
    "                log = res['log']\n",
    "                self.error = res['error']\n",
    "                run_info['why_error'] = res['why_error']\n",
    "                # Log file must have this to have finished properly\n",
    "                if log.find('finished simulation') == -1:\n",
    "                    run_info['error'] = True\n",
    "                    run_info.update({'error': True, 'why_error': \"Couldn't find finished simulation\"})\n",
    "    \n",
    "            else:\n",
    "                # Interactive output, for Jupyter\n",
    "                log = []\n",
    "                for path in tools.execute(runscript):\n",
    "                    self.vprint(path, end=\"\")\n",
    "                    log.append(path)\n",
    "    \n",
    "            self.log = log\n",
    "                    \n",
    "            if parse_output:\n",
    "                self.load_output()\n",
    "        except Exception as ex:\n",
    "            print('Run Aborted', ex)\n",
    "            self.error = True\n",
    "            run_info['why_error'] = str(ex)\n",
    "        finally:\n",
    "            run_info['run_time'] = time() - t1\n",
    "            run_info['run_error'] = self.error\n",
    "            \n",
    "            # Add run_info\n",
    "            self.output.update(run_info)\n",
    "            \n",
    "            # Return to init_dir\n",
    "            os.chdir(init_dir)                        \n",
    "        \n",
    "        self.finished = True\n",
    "    \n",
    "    def fingerprint(self):\n",
    "        \"\"\"\n",
    "        Data fingerprint using the input. \n",
    "        \"\"\"\n",
    "        return tools.fingerprint(self.input)\n",
    "                \n",
    "    def vprint(self, *args, **kwargs):\n",
    "        # Verbose print\n",
    "        if self.verbose:\n",
    "            print(*args, **kwargs)    \n",
    "    \n",
    "    \n",
    "    def write_input_file(self):\n",
    "        #TODO\n",
    "        #parsers.write_namelists(self.input, self.input_file)\n",
    "        pass\n",
    "        \n",
    "    # h5 writing\n",
    "    def write_input(self, h5):\n",
    "        #TODO\n",
    "        #writers.write_input_h5(h5, self.input)\n",
    "        pass\n",
    "    \n",
    "    def write_output(self, h5):\n",
    "        #TODO\n",
    "        writers.write_output_h5(h5, self.output)\n",
    "        \n",
    "    def write_screens(self, h5):\n",
    "        #writers.write_screens_h5(h5, self.screen)    \n",
    "        pass\n",
    "        \n",
    "    def archive(self, h5=None):\n",
    "        \"\"\"\n",
    "        Archive all data to an h5 handle or filename.\n",
    "        \n",
    "        If no file is given, a file based on the fingerprint will be created.\n",
    "        \n",
    "        \"\"\"\n",
    "        if not h5:\n",
    "            h5 = 'gpt_'+self.fingerprint()+'.h5'\n",
    "         \n",
    "        if isinstance(h5, str):\n",
    "            g = h5py.File(h5, 'w')\n",
    "            self.vprint(f'Archiving to file {h5}')\n",
    "        else:\n",
    "            g = h5\n",
    "        \n",
    "        # All input\n",
    "        self.write_input(g)\n",
    "\n",
    "        # All output\n",
    "        self.write_output(g)\n",
    "            \n",
    "        # Particles    \n",
    "        self.write_screens(g)          \n",
    "        \n",
    "        return h5\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = GPT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
